{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "from random import sample\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import os\n",
    "import torch\n",
    "import json \n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "from random import sample\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv(\"C:/PROJECTS/Abstractive Text Summarization/dataset/cnn_dailymail/train.csv\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "SUMMARY_LEN = 150\n",
    "TRAINNING_SIZE = 5000\n",
    "\n",
    "training_df = training_df.iloc[0:TRAINNING_SIZE,:].copy()\n",
    "\n",
    "training_article_ls = list(training_df['article'])\n",
    "training_highlight_ls = list(training_df['highlights'])\n",
    "\n",
    "del training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in sample(list(np.arange(len(training_article_ls))),3):\n",
    "    print('Original Text : ')\n",
    "    print(training_article_ls[index])\n",
    "\n",
    "    print('\\n\\nSummary Text : ')\n",
    "    print(training_highlight_ls[index])\n",
    "    \n",
    "    print('===========================================================================================================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['target_text','source_text'])\n",
    "df['target_text'] = training_highlight_ls\n",
    "df['source_text'] = ['summarize: '+item for item in training_article_ls] \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simplet5 import SimpleT5\n",
    "\n",
    "model = SimpleT5()\n",
    "model.from_pretrained(model_type=\"t5\", model_name=\"t5-base\")\n",
    "MAX_EPOCHS = 10\n",
    "\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "torch.utils.checkpoint\n",
    "\n",
    "model.train(train_df=df[0:(int)(0.7*TRAINNING_SIZE)],\n",
    "            eval_df=df[(int)(0.7*TRAINNING_SIZE):TRAINNING_SIZE], \n",
    "            source_max_token_len=MAX_LEN, \n",
    "            target_max_token_len=SUMMARY_LEN, \n",
    "            batch_size=4, max_epochs=MAX_EPOCHS, use_gpu=True)\n",
    "            \n",
    "model_path = ''\n",
    "rootdir = 'outputs/'\n",
    "for it in os.scandir(rootdir):\n",
    "    if it.is_dir():\n",
    "        if 'simplet5-epoch-'+(str)(MAX_EPOCHS-1) in it.path:\n",
    "            model_path = it.path\n",
    "            print(model_path)\n",
    "\n",
    "model.load_model(\"t5\",\"./\"+model_path, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tune_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in sample(list(np.arange(len(training_article_ls))),5):\n",
    "    print('Original Text : ')\n",
    "    print(training_article_ls[index])\n",
    "\n",
    "    Original_article = training_article_ls[index]\n",
    "\n",
    "    print('\\n\\nSummary Text : ')\n",
    "    print(training_highlight_ls[index])\n",
    "\n",
    "    Original_Summary = training_highlight_ls[index]\n",
    "\n",
    "    print('\\n\\nFine tuned Predicted Summary Text : ')\n",
    "    print(model.predict(training_article_ls[index]))\n",
    "\n",
    "    Predicted_Summary = training_article_ls[index]\n",
    "\n",
    "    rouge = Rouge()\n",
    "    BLEUscore = nltk.translate.bleu_score.sentence_bleu([Predicted_Summary], Original_Summary)\n",
    "    \n",
    "    print(\"-----------------\")\n",
    "\n",
    "    print(rouge.get_scores(Predicted_Summary, Original_Summary))\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    \n",
    "    print(BLEUscore)\n",
    "\n",
    "    print(\"-----------------\") \n",
    "\n",
    "\n",
    "    print('\\n\\nNot Fine tuned Predicted Summary Text : ')\n",
    "    preprocess_text = training_article_ls[index].strip().replace(\"\\n\",\"\")\n",
    "    t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "    tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "    summary_ids = no_tune_model.generate(tokenized_text,\n",
    "                                        num_beams=4,\n",
    "                                        no_repeat_ngram_size=2,\n",
    "                                        min_length=30,\n",
    "                                        max_length=SUMMARY_LEN,\n",
    "                                        early_stopping=True)\n",
    "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    print(output)\n",
    "    print('===========================================================================================================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
